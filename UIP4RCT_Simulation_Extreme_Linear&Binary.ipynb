{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27c4e256",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "import seaborn as sn\n",
    "import gc\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "from easydict import EasyDict as edict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from samplers import *\n",
    "from datgen import *\n",
    "\n",
    "import scipy.stats as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52af210a",
   "metadata": {},
   "source": [
    "# Continuous Outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a158377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_unit(i,\n",
    "                  D_lst,\n",
    "                  summaryDs_lst,\n",
    "                  method='BLR',\n",
    "                  bal_method='NearMatch',\n",
    "                  cov_adj=True,\n",
    "                  y_type='C',\n",
    "                  random_state=2021):\n",
    "    \n",
    "    D = D_lst[i]\n",
    "    summaryDs = summaryDs_lst[i]\n",
    "    result_dict = edict()\n",
    "    \n",
    "    if method == 'BLR':\n",
    "        result = BLR(D,cov_adj=cov_adj,\n",
    "                     y_type=y_type,\n",
    "                     random_state=random_state)\n",
    "        result_dict.theta1 = result['theta1']\n",
    "        result_dict.M = None\n",
    "        result_dict.pis = None\n",
    "        \n",
    "    elif method == 'UIP':\n",
    "        result = UIP_Dirichlet(D,summaryDs,\n",
    "                               bal_method=bal_method,\n",
    "                               cov_adj=cov_adj,\n",
    "                               y_type=y_type,\n",
    "                               gammas_ps=False,\n",
    "                               random_state=random_state)\n",
    "        result_dict.theta1 = result['theta1']\n",
    "        result_dict.M = result['M']\n",
    "        result_dict.pis = result['pis']\n",
    "        \n",
    "    return result\n",
    "\n",
    "\n",
    "def method_eval(theta_pred_mat,theta,trim_rate=0.005):\n",
    "    \n",
    "    if trim_rate==0:\n",
    "        bias = theta_pred_mat[:,0].mean()-theta[1]\n",
    "        rmse = np.sqrt(np.mean((theta_pred_mat[:,0]-theta[1])**2))\n",
    "        ci_width = np.mean(theta_pred_mat[:,2]-theta_pred_mat[:,1])\n",
    "        ci_coverage = np.mean((theta_pred_mat[:,2]>=theta[1])*(theta_pred_mat[:,1]<=theta[1]))\n",
    "        \n",
    "    else:\n",
    "        # prevent some rare outliers\n",
    "        bias = sp.trim_mean(theta_pred_mat[:,0],trim_rate)-theta[1]\n",
    "        rmse = np.sqrt(sp.trim_mean((theta_pred_mat[:,0]-theta[1])**2,trim_rate))\n",
    "        ci_width = sp.trim_mean(theta_pred_mat[:,2]-theta_pred_mat[:,1],trim_rate)\n",
    "        ci_coverage = sp.trim_mean((theta_pred_mat[:,2]>=theta[1])*(theta_pred_mat[:,1]<=theta[1]),trim_rate)\n",
    "    \n",
    "    return np.array([bias, rmse, ci_width, ci_coverage])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02f3d86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# date\n",
    "date = '0705'\n",
    "\n",
    "# simulation scenarios\n",
    "scenarios = [4,5]\n",
    "\n",
    "# replications & simulations\n",
    "reps = 200\n",
    "num_cores = 10\n",
    "random_state = 2021\n",
    "\n",
    "# cov_adj in RWD and RCT\n",
    "cov_adj_datgen = True\n",
    "cov_adj_pred = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f20bed1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nH = 500 # sample size for the historical data\n",
    "n = 200 # sample size for current data\n",
    "K = 3 # number of historical data\n",
    "rho = 0.1 # correlation coefficient\n",
    "d = 6 # dimension of coveriates\n",
    "y_type = 'C' # y_type: C => continuous / B=> Binary\n",
    "m_threshold = 0.1 # balance treshold\n",
    "\n",
    "# coefficient of the response surface\n",
    "theta = np.array([1,1]+[1]*d).astype('float')\n",
    "sigmat = rho*np.ones((d,d))+(1-rho)*np.eye(d)\n",
    "\n",
    "# treatment effect\n",
    "theta1 = {\n",
    "    '1': [1,1,1],\n",
    "    '2': [0.8,1.1,1.3],\n",
    "    '3': [0.8,1.1,1.3],\n",
    "    '4': [0.1,0.5,0.9],\n",
    "    '5': [2,3,4]\n",
    "}\n",
    "\n",
    "# parameter to generate covariates\n",
    "X_means = {'1':[0,0,0],\n",
    "           '2':[0,0,0],\n",
    "           '3':[0.5,1,1.5],\n",
    "           '4':[0.5,1,1.5],\n",
    "           '5':[0.5,1,1.5]}\n",
    "\n",
    "X_stds =  {'1':[1,1,1],\n",
    "           '2':[1,1,1],\n",
    "           '3':[0.5,1.5,2],\n",
    "           '4':[0.5,1.5,2],\n",
    "           '5':[0.5,1.5,2]}\n",
    "\n",
    "sig_err_k = [.5,.5,.5]\n",
    "sig_err = .5\n",
    "\n",
    "betas = [np.array([0,0]+[0.2]*2+[-0.2]*2),\n",
    "         np.array([1,1]+[1]*2+[-1]*2),\n",
    "         np.array([2,2]+[2]*2+[-2]*2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1a61769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Generation\n",
      "\n",
      "--------------- Scenario 4 ---------------\n",
      "Load Saved Historical Data!\n",
      "Load Saved RCT Data!\n",
      "Load Saved Summary Data!\n",
      "Balance Method: NearMatch\n",
      "NIP Complete!\n",
      "UIP Complete!\n",
      "                                  Bias      RMSE  CI Width  CI Coverage  \\\n",
      "Case       Bal_Method Method                                              \n",
      "Scenario 4 NearMatch  NIP     0.011511  0.072667  0.283409     0.939394   \n",
      "                      UIP    -0.021914  0.074391  0.273485     0.924242   \n",
      "\n",
      "                                $w_1$     $w_2$     $w_3$        $M$  \n",
      "Case       Bal_Method Method                                          \n",
      "Scenario 4 NearMatch  NIP         NaN       NaN       NaN        NaN  \n",
      "                      UIP     0.13983  0.292796  0.567374  71.699573  \n",
      "Balance Method: IPW\n",
      "NIP Complete!\n",
      "UIP Complete!\n",
      "                                  Bias      RMSE  CI Width  CI Coverage  \\\n",
      "Case       Bal_Method Method                                              \n",
      "Scenario 4 IPW        NIP     0.011511  0.072667  0.283409     0.939394   \n",
      "                      UIP    -0.020251  0.074071  0.274169     0.939394   \n",
      "\n",
      "                                 $w_1$     $w_2$     $w_3$        $M$  \n",
      "Case       Bal_Method Method                                           \n",
      "Scenario 4 IPW        NIP          NaN       NaN       NaN        NaN  \n",
      "                      UIP     0.144377  0.303507  0.552116  73.020328  \n",
      "Data Generation\n",
      "\n",
      "--------------- Scenario 5 ---------------\n",
      "Load Saved Historical Data!\n",
      "Load Saved RCT Data!\n",
      "Load Saved Summary Data!\n",
      "Balance Method: NearMatch\n",
      "NIP Complete!\n",
      "UIP Complete!\n",
      "                                  Bias      RMSE  CI Width  CI Coverage  \\\n",
      "Case       Bal_Method Method                                              \n",
      "Scenario 5 NearMatch  NIP     0.011511  0.072667  0.283409     0.939394   \n",
      "                      UIP     0.016967  0.074524  0.275486     0.914141   \n",
      "\n",
      "                                 $w_1$     $w_2$     $w_3$       $M$  \n",
      "Case       Bal_Method Method                                          \n",
      "Scenario 5 NearMatch  NIP          NaN       NaN       NaN       NaN  \n",
      "                      UIP     0.398443  0.348554  0.253003  1.827237  \n",
      "Balance Method: IPW\n",
      "NIP Complete!\n",
      "UIP Complete!\n",
      "                                  Bias      RMSE  CI Width  CI Coverage  \\\n",
      "Case       Bal_Method Method                                              \n",
      "Scenario 5 IPW        NIP     0.011511  0.072667  0.283409     0.939394   \n",
      "                      UIP     0.016597  0.074056  0.274857     0.929293   \n",
      "\n",
      "                                 $w_1$     $w_2$     $w_3$       $M$  \n",
      "Case       Bal_Method Method                                          \n",
      "Scenario 5 IPW        NIP          NaN       NaN       NaN       NaN  \n",
      "                      UIP     0.394889  0.347019  0.258092  1.858178  \n"
     ]
    }
   ],
   "source": [
    "metrics_dfs = []\n",
    "pis_lst = []\n",
    "M_lst = []\n",
    "\n",
    "for scenario in scenarios:\n",
    "    print('Data Generation\\n')\n",
    "    print('--------------- Scenario',scenario,'---------------')\n",
    "\n",
    "    save_folder = './results/{}C_outcome/scenario{}/'.format(date,scenario)\n",
    "\n",
    "    if not os.path.exists(save_folder):\n",
    "        print('Creat the folder!')\n",
    "        os.makedirs(save_folder)\n",
    "\n",
    "    # Generate the historical data\n",
    "    if not (os.path.exists(save_folder + 'scenario{}_histDs.npy'.format(scenario))):\n",
    "        print('Generate Historical Data!')\n",
    "\n",
    "        np.random.seed(2021)\n",
    "        histDs_lst = []\n",
    "\n",
    "        for i in tqdm(range(reps)):\n",
    "            histDs = edict()\n",
    "            histDs.RWDs = []\n",
    "            histDs.betas = []\n",
    "            histDs.thetas = []\n",
    "            histDs.ps_true = []\n",
    "\n",
    "            for k in range(K):\n",
    "                betak = betas[k]\n",
    "\n",
    "                thetak = theta.copy().astype('float')\n",
    "                thetak[1] = theta1[str(scenario)][k]\n",
    "                thetak[2:] = theta[2:].copy()+0.1*np.random.randn(d) if scenario>=2 else theta[2:].copy()\n",
    "            \n",
    "                sigmatk = np.sqrt(X_stds[str(scenario)][k])*rho*np.ones((d,d))+ \\\n",
    "                         (X_stds[str(scenario)][k]-np.sqrt(X_stds[str(scenario)][k])*rho)*np.eye(d)\n",
    "\n",
    "                Xk = np.random.multivariate_normal(X_means[str(scenario)][k]*np.ones(d),sigmatk,size=nH)\n",
    "                Xk[:,:int(0.4*d)] = np.array(Xk[:,:int(0.4*d)]>X_means[str(scenario)][k],dtype=float)\n",
    "\n",
    "                Tk, yk, psk_true = y_gen(Xk,thetak,betak,y_type=y_type,sig_err=sig_err_k[k])\n",
    "\n",
    "                histDs.RWDs.append((Xk,Tk,yk))\n",
    "                histDs.thetas.append(thetak)\n",
    "                histDs.betas.append(betak)\n",
    "                histDs.ps_true.append(psk_true)\n",
    "\n",
    "            histDs_lst.append(histDs)\n",
    "\n",
    "        np.save(save_folder+'scenario{}_histDs.npy'.format(scenario), np.array(histDs_lst))\n",
    "\n",
    "    else:\n",
    "\n",
    "        print('Load Saved Historical Data!')\n",
    "        histDs_lst = np.load(save_folder+'scenario{}_histDs.npy'.format(scenario),allow_pickle=True)\n",
    "\n",
    "\n",
    "    # Generate current study\n",
    "    if not (os.path.exists(save_folder + 'scenario{}_Ds.npy'.format(scenario))):\n",
    "        print('Generate Current RCT Data!')\n",
    "\n",
    "        np.random.seed(2021)\n",
    "        Ds_lst = []\n",
    "\n",
    "        for i in tqdm(range(reps)):\n",
    "            D = edict()\n",
    "            D.X = np.random.multivariate_normal(np.zeros(d),sigmat,size=n)\n",
    "            D.X[:,:int(0.4*d)] = np.array(D.X[:,:int(0.4*d)]>0,dtype=float)\n",
    "            D.T, D.y, D.ps_true = y_gen(D.X,theta,\n",
    "                                        np.zeros(d),\n",
    "                                        y_type=y_type,\n",
    "                                        sig_err=sig_err)\n",
    "            Ds_lst.append(D)\n",
    "\n",
    "        np.save(save_folder+'scenario{}_Ds.npy'.format(scenario), np.array(Ds_lst))\n",
    "\n",
    "    else:\n",
    "\n",
    "        print('Load Saved RCT Data!')\n",
    "        Ds_lst = np.load(save_folder+'scenario{}_Ds.npy'.format(scenario),allow_pickle=True)\n",
    "\n",
    "\n",
    "    # Generate the aggregate data based on historical data\n",
    "    if not os.path.exists(save_folder + 'scenario{}_summaryDs.bin'.format(scenario)):\n",
    "        print('Generate Current Summary Data!')\n",
    "        from balance_methods import *\n",
    "\n",
    "        numpy2ri.activate()\n",
    "        pandas2ri.activate()\n",
    "\n",
    "        summaryDs_lst = []\n",
    "\n",
    "        for i in tqdm(range(reps)):\n",
    "            summaryDs = edict()\n",
    "            summaryDs.ps_pred = []\n",
    "            summaryDs.beta_hat = []\n",
    "            summaryDs.NearMatch = []\n",
    "            summaryDs.IPW = []\n",
    "\n",
    "            histDs = histDs_lst[i]\n",
    "\n",
    "            for k in range(K):\n",
    "                Xk,Tk,yk = histDs.RWDs[k]\n",
    "                clf = LogisticRegression()\n",
    "                clf.fit(Xk,Tk)\n",
    "                psk_pred = clf.predict_proba(Xk)[:,1]\n",
    "                betak_hat = np.array([clf.intercept_[0]]+clf.coef_.flatten().tolist())\n",
    "\n",
    "                summaryDs.ps_pred.append(psk_pred)\n",
    "                summaryDs.beta_hat.append(betak_hat)\n",
    "\n",
    "                # nearest matching\n",
    "                mdata, summary_fit, bal_out = matchit_wrapper(yk,Tk,Xk,\n",
    "                                                              y_type=y_type,\n",
    "                                                  cov_adj=cov_adj_datgen,\n",
    "                                                  method='nearest',\n",
    "                                                  estimand='ATT',\n",
    "                                                  replace=False)\n",
    "                summaryDs.NearMatch.append(((mdata['weights']>0).sum(), \n",
    "                                            (np.sum(np.abs(bal_out[0]['Diff.Adj'][1:]) < m_threshold))/(d), \n",
    "                                            summary_fit, mdata))\n",
    "                \n",
    "                # inverse probability weighting\n",
    "                wdata, summary_fit, bal_out = weightit_wrapper(yk,Tk,Xk,\n",
    "                                                  y_type=y_type,\n",
    "                                                  cov_adj=cov_adj_datgen,\n",
    "                                                  method='ps',\n",
    "                                                  estimand='ATT',\n",
    "                                                  link='logit')\n",
    "                summaryDs.IPW.append(((wdata['weights']>0).sum(), \n",
    "                            (np.sum(np.abs(bal_out[0]['Diff.Adj'][1:]) < m_threshold))/(d), \n",
    "                            summary_fit, wdata))\n",
    "                \n",
    "\n",
    "            summaryDs_lst.append(summaryDs)\n",
    "\n",
    "        file=open(save_folder+'scenario{}_summaryDs.bin'.format(scenario),\"wb\")\n",
    "        pickle.dump(summaryDs_lst, file) \n",
    "        file.close()\n",
    "\n",
    "        numpy2ri.deactivate()\n",
    "        pandas2ri.deactivate()\n",
    "\n",
    "    else:\n",
    "\n",
    "        print('Load Saved Summary Data!')\n",
    "        summaryDs_lst = pickle.load(open(save_folder+'scenario{}_summaryDs.bin'.format(scenario),\"rb\"))\n",
    "    \n",
    "    for bal_method in ['NearMatch','IPW']:\n",
    "        \n",
    "        print('Balance Method:',bal_method)\n",
    "\n",
    "        # NIP\n",
    "        if not os.path.exists(save_folder + 'scenario{}_blr_results.bin'.format(scenario)):\n",
    "            trace_blr_lst = Parallel(n_jobs=num_cores)(delayed(parallel_unit)(i, Ds_lst, \n",
    "                                                                               summaryDs_lst, \n",
    "                                                                               method='BLR',\n",
    "                                                                               bal_method=bal_method,\n",
    "                                                                               cov_adj=cov_adj_pred,\n",
    "                                                                               y_type=y_type,\n",
    "                                                                              random_state=random_state) \n",
    "                                                                              for i in tqdm(range(reps)))\n",
    "            file=open(save_folder + 'scenario{}_blr_results.bin'.format(scenario),\"wb\")\n",
    "            pickle.dump(trace_blr_lst, file) \n",
    "            file.close()\n",
    "\n",
    "        else:\n",
    "            trace_blr_lst = pickle.load(open(save_folder + 'scenario{}_blr_results.bin'.format(scenario),\"rb\"))\n",
    "\n",
    "        theta_pred_blr_mat = np.array([np.array([(trace_blr_lst[i]['theta1']).mean(),\n",
    "                                                 np.quantile((trace_blr_lst[i]['theta1']),0.025),\n",
    "                                                 np.quantile((trace_blr_lst[i]['theta1']),0.975)]) for i in range(reps)])\n",
    "\n",
    "        del trace_blr_lst\n",
    "        gc.collect()\n",
    "        print('NIP Complete!')\n",
    "\n",
    "\n",
    "        # UIP\n",
    "        if not os.path.exists(save_folder + bal_method +'_scenario{}_uip_results.bin'.format(scenario)):\n",
    "            try:\n",
    "                trace_uip_lst = Parallel(n_jobs=num_cores)(delayed(parallel_unit)(i, Ds_lst, \n",
    "                                                                                    summaryDs_lst, \n",
    "                                                                                    method='UIP',\n",
    "                                                                                    bal_method=bal_method,\n",
    "                                                                                    cov_adj=cov_adj_pred,\n",
    "                                                                                    y_type=y_type,\n",
    "                                                                                  random_state=random_state) \n",
    "                                                                                for i in tqdm(range(reps)))\n",
    "            except:\n",
    "                trace_uip_lst = Parallel(n_jobs=1)(delayed(parallel_unit)(i, Ds_lst, \n",
    "                                                                                    summaryDs_lst, \n",
    "                                                                                    method='UIP',\n",
    "                                                                                    bal_method=bal_method,\n",
    "                                                                                    cov_adj=cov_adj_pred,\n",
    "                                                                                    y_type=y_type,\n",
    "                                                                                  random_state=random_state) \n",
    "                                                                                for i in tqdm(range(reps)))\n",
    "            file=open(save_folder + bal_method +'_scenario{}_uip_results.bin'.format(scenario),\"wb\")\n",
    "            pickle.dump(trace_uip_lst, file) \n",
    "            file.close()\n",
    "\n",
    "        else:\n",
    "\n",
    "            trace_uip_lst = pickle.load(open(save_folder + bal_method +'_scenario{}_uip_results.bin'.format(scenario),\"rb\"))\n",
    "\n",
    "\n",
    "        theta_pred_uip_mat = np.array([np.array([(trace_uip_lst[i]['theta1']).mean(),\n",
    "                                                 np.quantile((trace_uip_lst[i]['theta1']),0.025),\n",
    "                                                 np.quantile((trace_uip_lst[i]['theta1']),0.975)]) for i in range(reps)])\n",
    "        uip_pis_array = np.array([trace_uip_lst[i]['pis'].mean(axis=0) for i in range(reps)])\n",
    "        uip_M_array = np.array([trace_uip_lst[i]['M'].mean(axis=0) for i in range(reps)])\n",
    "\n",
    "        del trace_uip_lst\n",
    "        gc.collect()\n",
    "        print('UIP Complete!')\n",
    "\n",
    "        pis_lst.append((uip_pis_array))\n",
    "        M_lst.append((uip_M_array))\n",
    "\n",
    "        # saving\n",
    "        # evaluation metrics\n",
    "        uip_df = pd.DataFrame(np.array([np.nan*np.ones(K),\n",
    "                           uip_pis_array.mean(axis=0)]),columns=['$w_{}$'.format(i+1) for i in range(K)])\n",
    "        uip_df['$M$'] = [np.nan,\n",
    "                         uip_M_array.mean(axis=0)]\n",
    "\n",
    "\n",
    "        metrics_array = np.array([method_eval(theta_pred_blr_mat,theta),\n",
    "                                  method_eval(theta_pred_uip_mat,theta)])\n",
    "        metrics_df = pd.DataFrame(metrics_array,columns=['Bias','RMSE','CI Width','CI Coverage'])\n",
    "        metrics_df['Method'] = ['NIP','UIP']\n",
    "        metrics_df['Case'] = 'Scenario {}'.format(scenario)\n",
    "        metrics_df['Bal_Method'] = bal_method\n",
    "        metrics_df = pd.concat([metrics_df,uip_df],axis=1)\n",
    "\n",
    "        print(metrics_df.set_index(['Case','Bal_Method','Method']))\n",
    "\n",
    "        metrics_df.set_index(['Case','Bal_Method','Method']).to_csv(save_folder+bal_method+'_metric_df.csv')\n",
    "\n",
    "        metrics_dfs.append(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ea0ab44",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Bias</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>CI Width</th>\n",
       "      <th>CI Coverage</th>\n",
       "      <th>$w_1$</th>\n",
       "      <th>$w_2$</th>\n",
       "      <th>$w_3$</th>\n",
       "      <th>$M$</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Case</th>\n",
       "      <th>Method</th>\n",
       "      <th>Bal_Method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Scenario 4</th>\n",
       "      <th>NIP</th>\n",
       "      <th>NearMatch</th>\n",
       "      <td>0.011511</td>\n",
       "      <td>0.072667</td>\n",
       "      <td>0.283409</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UIP</th>\n",
       "      <th>NearMatch</th>\n",
       "      <td>-0.021914</td>\n",
       "      <td>0.074391</td>\n",
       "      <td>0.273485</td>\n",
       "      <td>0.924242</td>\n",
       "      <td>0.139830</td>\n",
       "      <td>0.292796</td>\n",
       "      <td>0.567374</td>\n",
       "      <td>71.699573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIP</th>\n",
       "      <th>IPW</th>\n",
       "      <td>0.011511</td>\n",
       "      <td>0.072667</td>\n",
       "      <td>0.283409</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UIP</th>\n",
       "      <th>IPW</th>\n",
       "      <td>-0.020251</td>\n",
       "      <td>0.074071</td>\n",
       "      <td>0.274169</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.144377</td>\n",
       "      <td>0.303507</td>\n",
       "      <td>0.552116</td>\n",
       "      <td>73.020328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Scenario 5</th>\n",
       "      <th>NIP</th>\n",
       "      <th>NearMatch</th>\n",
       "      <td>0.011511</td>\n",
       "      <td>0.072667</td>\n",
       "      <td>0.283409</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UIP</th>\n",
       "      <th>NearMatch</th>\n",
       "      <td>0.016967</td>\n",
       "      <td>0.074524</td>\n",
       "      <td>0.275486</td>\n",
       "      <td>0.914141</td>\n",
       "      <td>0.398443</td>\n",
       "      <td>0.348554</td>\n",
       "      <td>0.253003</td>\n",
       "      <td>1.827237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIP</th>\n",
       "      <th>IPW</th>\n",
       "      <td>0.011511</td>\n",
       "      <td>0.072667</td>\n",
       "      <td>0.283409</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UIP</th>\n",
       "      <th>IPW</th>\n",
       "      <td>0.016597</td>\n",
       "      <td>0.074056</td>\n",
       "      <td>0.274857</td>\n",
       "      <td>0.929293</td>\n",
       "      <td>0.394889</td>\n",
       "      <td>0.347019</td>\n",
       "      <td>0.258092</td>\n",
       "      <td>1.858178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Bias      RMSE  CI Width  CI Coverage  \\\n",
       "Case       Method Bal_Method                                              \n",
       "Scenario 4 NIP    NearMatch   0.011511  0.072667  0.283409     0.939394   \n",
       "           UIP    NearMatch  -0.021914  0.074391  0.273485     0.924242   \n",
       "           NIP    IPW         0.011511  0.072667  0.283409     0.939394   \n",
       "           UIP    IPW        -0.020251  0.074071  0.274169     0.939394   \n",
       "Scenario 5 NIP    NearMatch   0.011511  0.072667  0.283409     0.939394   \n",
       "           UIP    NearMatch   0.016967  0.074524  0.275486     0.914141   \n",
       "           NIP    IPW         0.011511  0.072667  0.283409     0.939394   \n",
       "           UIP    IPW         0.016597  0.074056  0.274857     0.929293   \n",
       "\n",
       "                                 $w_1$     $w_2$     $w_3$        $M$  \n",
       "Case       Method Bal_Method                                           \n",
       "Scenario 4 NIP    NearMatch        NaN       NaN       NaN        NaN  \n",
       "           UIP    NearMatch   0.139830  0.292796  0.567374  71.699573  \n",
       "           NIP    IPW              NaN       NaN       NaN        NaN  \n",
       "           UIP    IPW         0.144377  0.303507  0.552116  73.020328  \n",
       "Scenario 5 NIP    NearMatch        NaN       NaN       NaN        NaN  \n",
       "           UIP    NearMatch   0.398443  0.348554  0.253003   1.827237  \n",
       "           NIP    IPW              NaN       NaN       NaN        NaN  \n",
       "           UIP    IPW         0.394889  0.347019  0.258092   1.858178  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_all = pd.concat(metrics_dfs)\n",
    "metrics_all.set_index(['Case','Method','Bal_Method'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8bbce6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_all.set_index(['Case','Method','Bal_Method']).to_csv('./results/{}C_outcome/metric_df_extreme.csv'.format(date))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ebc509",
   "metadata": {},
   "source": [
    "# Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4a7bb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "nH = 500 # sample size for the historical data\n",
    "n = 200 # sample size for current data\n",
    "K = 3 # number of historical data\n",
    "rho = 0.1 # correlation coefficient\n",
    "d = 6 # dimension\n",
    "y_type = 'B' # response type\n",
    "m_threshold = 0.1 # balance treshold\n",
    "\n",
    "# coefficient of the response surface\n",
    "theta = np.array([-1,1]+[0.1]*d).astype('float')\n",
    "sigmat = rho*np.ones((d,d))+(1-rho)*np.eye(d)\n",
    "\n",
    "\n",
    "# treatment effect\n",
    "theta1 = {\n",
    "    '1': [1,1,1],\n",
    "    '2': [0.8,1.1,1.3],\n",
    "    '3': [0.8,1.1,1.3],\n",
    "    '4': [0.5,2.5,4.5],\n",
    "    '5': [5,7,9]\n",
    "}\n",
    "\n",
    "# parameter to generate covariates\n",
    "X_means = {'1':[0,0,0],\n",
    "           '2':[0,0,0],\n",
    "           '3':[0.5,1,1.5],\n",
    "           '4':[0.5,1,1.5],\n",
    "           '5':[0.5,1,1.5]}\n",
    "\n",
    "X_stds =  {'1':[1,1,1],\n",
    "           '2':[1,1,1],\n",
    "           '3':[0.5,1.5,2],\n",
    "           '4':[0.5,1.5,2],\n",
    "           '5':[0.5,1.5,2]}\n",
    "\n",
    "# coefficients to generate the propensity scores\n",
    "betas = [np.array([0,0]+[0.2]*2+[-0.2]*2),\n",
    "         np.array([1,1]+[1]*2+[-1]*2),\n",
    "         np.array([2,2]+[2]*2+[-2]*2)]\n",
    "\n",
    "num_cores = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e5f7353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Generation\n",
      "\n",
      "--------------- Scenario 4 ---------------\n",
      "Load Saved Historical Data!\n",
      "Load Saved RCT Data!\n",
      "Load Saved Summary Data!\n",
      "Balance Method: NearMatch\n",
      "NIP Complete!\n",
      "UIP Complete!\n",
      "                                  Bias      RMSE  CI Width  CI Coverage  \\\n",
      "Case       Bal_Method Method                                              \n",
      "Scenario 4 NearMatch  NIP     0.060925  0.345514  1.238014     0.929293   \n",
      "                      UIP     0.207158  0.376190  1.233114     0.893939   \n",
      "\n",
      "                                 $w_1$     $w_2$     $w_3$        $M$  \n",
      "Case       Bal_Method Method                                           \n",
      "Scenario 4 NearMatch  NIP          NaN       NaN       NaN        NaN  \n",
      "                      UIP     0.527001  0.303782  0.169218  95.718702  \n",
      "Balance Method: IPW\n",
      "NIP Complete!\n",
      "UIP Complete!\n",
      "                                  Bias      RMSE  CI Width  CI Coverage  \\\n",
      "Case       Bal_Method Method                                              \n",
      "Scenario 4 IPW        NIP     0.060925  0.345514  1.238014     0.929293   \n",
      "                      UIP     0.207905  0.378133  1.236464     0.878788   \n",
      "\n",
      "                                 $w_1$     $w_2$     $w_3$        $M$  \n",
      "Case       Bal_Method Method                                           \n",
      "Scenario 4 IPW        NIP          NaN       NaN       NaN        NaN  \n",
      "                      UIP     0.544429  0.299113  0.156458  93.798194  \n",
      "Data Generation\n",
      "\n",
      "--------------- Scenario 5 ---------------\n",
      "Load Saved Historical Data!\n",
      "Load Saved RCT Data!\n",
      "Load Saved Summary Data!\n",
      "Balance Method: NearMatch\n",
      "NIP Complete!\n",
      "UIP Complete!\n",
      "                                  Bias      RMSE  CI Width  CI Coverage  \\\n",
      "Case       Bal_Method Method                                              \n",
      "Scenario 5 NearMatch  NIP     0.060925  0.345514  1.238014     0.929293   \n",
      "                      UIP     0.136330  0.375055  1.290145     0.929293   \n",
      "\n",
      "                                 $w_1$     $w_2$     $w_3$       $M$  \n",
      "Case       Bal_Method Method                                          \n",
      "Scenario 5 NearMatch  NIP          NaN       NaN       NaN       NaN  \n",
      "                      UIP     0.547831  0.260926  0.191242  11.97123  \n",
      "Balance Method: IPW\n",
      "NIP Complete!\n",
      "UIP Complete!\n",
      "                                  Bias      RMSE  CI Width  CI Coverage  \\\n",
      "Case       Bal_Method Method                                              \n",
      "Scenario 5 IPW        NIP     0.060925  0.345514  1.238014     0.929293   \n",
      "                      UIP     0.131011  0.374231  1.288353     0.939394   \n",
      "\n",
      "                                 $w_1$     $w_2$     $w_3$        $M$  \n",
      "Case       Bal_Method Method                                           \n",
      "Scenario 5 IPW        NIP          NaN       NaN       NaN        NaN  \n",
      "                      UIP     0.466399  0.312096  0.221505  14.140089  \n"
     ]
    }
   ],
   "source": [
    "metrics_dfs = []\n",
    "pis_lst = []\n",
    "M_lst = []\n",
    "\n",
    "for scenario in scenarios:\n",
    "    print('Data Generation\\n')\n",
    "    print('--------------- Scenario',scenario,'---------------')\n",
    "\n",
    "    save_folder = './results/{}B_outcome/scenario{}/'.format(date,scenario)\n",
    "\n",
    "    if not os.path.exists(save_folder):\n",
    "        print('Creat the folder!')\n",
    "        os.makedirs(save_folder)\n",
    "\n",
    "    # Generate the historical data\n",
    "    if not (os.path.exists(save_folder + 'scenario{}_histDs.npy'.format(scenario))):\n",
    "        print('Generate Historical Data!')\n",
    "\n",
    "        np.random.seed(2021)\n",
    "        histDs_lst = []\n",
    "\n",
    "        for i in tqdm(range(reps)):\n",
    "            histDs = edict()\n",
    "            histDs.RWDs = []\n",
    "            histDs.betas = []\n",
    "            histDs.thetas = []\n",
    "            histDs.ps_true = []\n",
    "\n",
    "            for k in range(K):\n",
    "                betak = betas[k]\n",
    "\n",
    "                thetak = theta.copy().astype('float')\n",
    "                thetak[1] = theta1[str(scenario)][k]\n",
    "                thetak[2:] = theta[2:].copy()+0.1*np.random.randn(d) if scenario>=2 else theta[2:].copy()\n",
    "            \n",
    "                sigmatk = np.sqrt(X_stds[str(scenario)][k])*rho*np.ones((d,d))+(X_stds[str(scenario)][k]-np.sqrt(X_stds[str(scenario)][k])*rho)*np.eye(d)\n",
    "\n",
    "                Xk = np.random.multivariate_normal(X_means[str(scenario)][k]*np.ones(d),sigmatk,size=nH)\n",
    "                Xk[:,:int(0.4*d)] = np.array(Xk[:,:int(0.4*d)]>X_means[str(scenario)][k],dtype=float)\n",
    "\n",
    "                Tk, yk, psk_true = y_gen(Xk,thetak,betak,y_type=y_type)\n",
    "\n",
    "                histDs.RWDs.append((Xk,Tk,yk))\n",
    "                histDs.thetas.append(thetak)\n",
    "                histDs.betas.append(betak)\n",
    "                histDs.ps_true.append(psk_true)\n",
    "\n",
    "            histDs_lst.append(histDs)\n",
    "\n",
    "        np.save(save_folder+'scenario{}_histDs.npy'.format(scenario), np.array(histDs_lst))\n",
    "\n",
    "    else:\n",
    "\n",
    "        print('Load Saved Historical Data!')\n",
    "        histDs_lst = np.load(save_folder+'scenario{}_histDs.npy'.format(scenario),allow_pickle=True)\n",
    "\n",
    "\n",
    "    # Generate current study\n",
    "    if not (os.path.exists(save_folder + 'scenario{}_Ds.npy'.format(scenario))):\n",
    "        print('Generate Current RCT Data!')\n",
    "\n",
    "        np.random.seed(2021)\n",
    "        Ds_lst = []\n",
    "\n",
    "        for i in tqdm(range(reps)):\n",
    "            D = edict()\n",
    "            D.X = np.random.multivariate_normal(np.zeros(d),sigmat,size=n)\n",
    "            D.X[:,:int(0.4*d)] = np.array(D.X[:,:int(0.4*d)]>0,dtype=float)\n",
    "            D.T, D.y, D.ps_true = y_gen(D.X,theta,np.zeros(d),y_type=y_type)\n",
    "            Ds_lst.append(D)\n",
    "\n",
    "        np.save(save_folder+'scenario{}_Ds.npy'.format(scenario), np.array(Ds_lst))\n",
    "\n",
    "    else:\n",
    "\n",
    "        print('Load Saved RCT Data!')\n",
    "        Ds_lst = np.load(save_folder+'scenario{}_Ds.npy'.format(scenario),allow_pickle=True)\n",
    "\n",
    "\n",
    "    # Generate the summary info based on historical data\n",
    "    if not os.path.exists(save_folder + 'scenario{}_summaryDs.bin'.format(scenario)):\n",
    "        print('Generate Current Summary Data!')\n",
    "        from balance_methods import *\n",
    "\n",
    "        numpy2ri.activate()\n",
    "        pandas2ri.activate()\n",
    "\n",
    "        summaryDs_lst = []\n",
    "\n",
    "        for i in tqdm(range(reps)):\n",
    "            summaryDs = edict()\n",
    "            summaryDs.ps_pred = []\n",
    "            summaryDs.beta_hat = []\n",
    "            summaryDs.NearMatch = []\n",
    "            summaryDs.IPW = []\n",
    "\n",
    "            histDs = histDs_lst[i]\n",
    "\n",
    "            for k in range(K):\n",
    "                Xk,Tk,yk = histDs.RWDs[k]\n",
    "                clf = LogisticRegression()\n",
    "                clf.fit(Xk,Tk)\n",
    "                psk_pred = clf.predict_proba(Xk)[:,1]\n",
    "                betak_hat = np.array([clf.intercept_[0]]+clf.coef_.flatten().tolist())\n",
    "\n",
    "                summaryDs.ps_pred.append(psk_pred)\n",
    "                summaryDs.beta_hat.append(betak_hat)\n",
    "\n",
    "                # nearest matching\n",
    "                mdata, summary_fit, bal_out = matchit_wrapper(yk,Tk,Xk,\n",
    "                                                              y_type=y_type,\n",
    "                                                  cov_adj=cov_adj_datgen,\n",
    "                                                  method='nearest',\n",
    "                                                  estimand='ATT',\n",
    "                                                  replace=False)\n",
    "                summaryDs.NearMatch.append(((mdata['weights']>0).sum(), \n",
    "                                            (np.sum(np.abs(bal_out[0]['Diff.Adj'][1:]) < m_threshold))/(d), \n",
    "                                            summary_fit, mdata))\n",
    "                \n",
    "                # inverse probability weighting\n",
    "                wdata, summary_fit, bal_out = weightit_wrapper(yk,Tk,Xk,\n",
    "                                                  y_type=y_type,\n",
    "                                                  cov_adj=cov_adj_datgen,\n",
    "                                                  method='ps',\n",
    "                                                  estimand='ATT',\n",
    "                                                  link='logit')\n",
    "                summaryDs.IPW.append(((wdata['weights']>0).sum(), \n",
    "                            (np.sum(np.abs(bal_out[0]['Diff.Adj'][1:]) < m_threshold))/(d), \n",
    "                            summary_fit, wdata))\n",
    "                \n",
    "\n",
    "            summaryDs_lst.append(summaryDs)\n",
    "\n",
    "        file=open(save_folder+'scenario{}_summaryDs.bin'.format(scenario),\"wb\")\n",
    "        pickle.dump(summaryDs_lst, file) \n",
    "        file.close()\n",
    "\n",
    "        numpy2ri.deactivate()\n",
    "        pandas2ri.deactivate()\n",
    "\n",
    "    else:\n",
    "\n",
    "        print('Load Saved Summary Data!')\n",
    "        summaryDs_lst = pickle.load(open(save_folder+'scenario{}_summaryDs.bin'.format(scenario),\"rb\"))\n",
    "    \n",
    "    for bal_method in ['NearMatch','IPW']:\n",
    "        \n",
    "        print('Balance Method:',bal_method)\n",
    "\n",
    "        # NIP\n",
    "        if not os.path.exists(save_folder + 'scenario{}_blr_results.bin'.format(scenario)):\n",
    "            trace_blr_lst = Parallel(n_jobs=num_cores)(delayed(parallel_unit)(i, Ds_lst, \n",
    "                                                                               summaryDs_lst, \n",
    "                                                                               method='BLR',\n",
    "                                                                               bal_method=bal_method,\n",
    "                                                                               cov_adj=cov_adj_pred,\n",
    "                                                                               y_type=y_type,\n",
    "                                                                              random_state=random_state) \n",
    "                                                                              for i in tqdm(range(reps)))\n",
    "            file=open(save_folder + 'scenario{}_blr_results.bin'.format(scenario),\"wb\")\n",
    "            pickle.dump(trace_blr_lst, file) \n",
    "            file.close()\n",
    "\n",
    "        else:\n",
    "            trace_blr_lst = pickle.load(open(save_folder + 'scenario{}_blr_results.bin'.format(scenario),\"rb\"))\n",
    "\n",
    "        theta_pred_blr_mat = np.array([np.array([(trace_blr_lst[i]['theta1']).mean(),\n",
    "                                                 np.quantile((trace_blr_lst[i]['theta1']),0.025),\n",
    "                                                 np.quantile((trace_blr_lst[i]['theta1']),0.975)]) for i in range(reps)])\n",
    "\n",
    "        del trace_blr_lst\n",
    "        gc.collect()\n",
    "        print('NIP Complete!')\n",
    "\n",
    "\n",
    "        # UIP\n",
    "        if not os.path.exists(save_folder + bal_method +'_scenario{}_uip_results.bin'.format(scenario)):\n",
    "            try:\n",
    "                trace_uip_lst = Parallel(n_jobs=num_cores)(delayed(parallel_unit)(i, Ds_lst, \n",
    "                                                                                    summaryDs_lst, \n",
    "                                                                                    method='UIP',\n",
    "                                                                                    bal_method=bal_method,\n",
    "                                                                                    cov_adj=cov_adj_pred,\n",
    "                                                                                    y_type=y_type,\n",
    "                                                                                  random_state=random_state) \n",
    "                                                                                for i in tqdm(range(reps)))\n",
    "            except:\n",
    "                trace_uip_lst = Parallel(n_jobs=1)(delayed(parallel_unit)(i, Ds_lst, \n",
    "                                                                                    summaryDs_lst, \n",
    "                                                                                    method='UIP',\n",
    "                                                                                    bal_method=bal_method,\n",
    "                                                                                    cov_adj=cov_adj_pred,\n",
    "                                                                                    y_type=y_type,\n",
    "                                                                                  random_state=random_state) \n",
    "                                                                                for i in tqdm(range(reps)))\n",
    "            file=open(save_folder + bal_method +'_scenario{}_uip_results.bin'.format(scenario),\"wb\")\n",
    "            pickle.dump(trace_uip_lst, file) \n",
    "            file.close()\n",
    "\n",
    "        else:\n",
    "\n",
    "            trace_uip_lst = pickle.load(open(save_folder + bal_method +'_scenario{}_uip_results.bin'.format(scenario),\"rb\"))\n",
    "\n",
    "\n",
    "        theta_pred_uip_mat = np.array([np.array([(trace_uip_lst[i]['theta1']).mean(),\n",
    "                                                 np.quantile((trace_uip_lst[i]['theta1']),0.025),\n",
    "                                                 np.quantile((trace_uip_lst[i]['theta1']),0.975)]) for i in range(reps)])\n",
    "        uip_pis_array = np.array([trace_uip_lst[i]['pis'].mean(axis=0) for i in range(reps)])\n",
    "        uip_M_array = np.array([trace_uip_lst[i]['M'].mean(axis=0) for i in range(reps)])\n",
    "\n",
    "        del trace_uip_lst\n",
    "        gc.collect()\n",
    "        print('UIP Complete!')\n",
    "\n",
    "        pis_lst.append((uip_pis_array))\n",
    "        M_lst.append((uip_M_array))\n",
    "\n",
    "        # saving\n",
    "        # evaluation metrics\n",
    "        uip_df = pd.DataFrame(np.array([np.nan*np.ones(K),\n",
    "                           uip_pis_array.mean(axis=0)]),columns=['$w_{}$'.format(i+1) for i in range(K)])\n",
    "        uip_df['$M$'] = [np.nan,\n",
    "                         uip_M_array.mean(axis=0)]\n",
    "\n",
    "\n",
    "        metrics_array = np.array([method_eval(theta_pred_blr_mat,theta),\n",
    "                                  method_eval(theta_pred_uip_mat,theta)])\n",
    "        metrics_df = pd.DataFrame(metrics_array,columns=['Bias','RMSE','CI Width','CI Coverage'])\n",
    "        metrics_df['Method'] = ['NIP','UIP']\n",
    "        metrics_df['Case'] = 'Scenario {}'.format(scenario)\n",
    "        metrics_df['Bal_Method'] = bal_method\n",
    "        metrics_df = pd.concat([metrics_df,uip_df],axis=1)\n",
    "\n",
    "        print(metrics_df.set_index(['Case','Bal_Method','Method']))\n",
    "\n",
    "        metrics_df.set_index(['Case','Bal_Method','Method']).to_csv(save_folder+bal_method+'_metric_df.csv')\n",
    "\n",
    "        metrics_dfs.append(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff65e089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Bias</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>CI Width</th>\n",
       "      <th>CI Coverage</th>\n",
       "      <th>$w_1$</th>\n",
       "      <th>$w_2$</th>\n",
       "      <th>$w_3$</th>\n",
       "      <th>$M$</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Case</th>\n",
       "      <th>Method</th>\n",
       "      <th>Bal_Method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Scenario 4</th>\n",
       "      <th>NIP</th>\n",
       "      <th>NearMatch</th>\n",
       "      <td>0.060925</td>\n",
       "      <td>0.345514</td>\n",
       "      <td>1.238014</td>\n",
       "      <td>0.929293</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UIP</th>\n",
       "      <th>NearMatch</th>\n",
       "      <td>0.207158</td>\n",
       "      <td>0.376190</td>\n",
       "      <td>1.233114</td>\n",
       "      <td>0.893939</td>\n",
       "      <td>0.527001</td>\n",
       "      <td>0.303782</td>\n",
       "      <td>0.169218</td>\n",
       "      <td>95.718702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIP</th>\n",
       "      <th>IPW</th>\n",
       "      <td>0.060925</td>\n",
       "      <td>0.345514</td>\n",
       "      <td>1.238014</td>\n",
       "      <td>0.929293</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UIP</th>\n",
       "      <th>IPW</th>\n",
       "      <td>0.207905</td>\n",
       "      <td>0.378133</td>\n",
       "      <td>1.236464</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.544429</td>\n",
       "      <td>0.299113</td>\n",
       "      <td>0.156458</td>\n",
       "      <td>93.798194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Scenario 5</th>\n",
       "      <th>NIP</th>\n",
       "      <th>NearMatch</th>\n",
       "      <td>0.060925</td>\n",
       "      <td>0.345514</td>\n",
       "      <td>1.238014</td>\n",
       "      <td>0.929293</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UIP</th>\n",
       "      <th>NearMatch</th>\n",
       "      <td>0.136330</td>\n",
       "      <td>0.375055</td>\n",
       "      <td>1.290145</td>\n",
       "      <td>0.929293</td>\n",
       "      <td>0.547831</td>\n",
       "      <td>0.260926</td>\n",
       "      <td>0.191242</td>\n",
       "      <td>11.971230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIP</th>\n",
       "      <th>IPW</th>\n",
       "      <td>0.060925</td>\n",
       "      <td>0.345514</td>\n",
       "      <td>1.238014</td>\n",
       "      <td>0.929293</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UIP</th>\n",
       "      <th>IPW</th>\n",
       "      <td>0.131011</td>\n",
       "      <td>0.374231</td>\n",
       "      <td>1.288353</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.466399</td>\n",
       "      <td>0.312096</td>\n",
       "      <td>0.221505</td>\n",
       "      <td>14.140089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Bias      RMSE  CI Width  CI Coverage  \\\n",
       "Case       Method Bal_Method                                              \n",
       "Scenario 4 NIP    NearMatch   0.060925  0.345514  1.238014     0.929293   \n",
       "           UIP    NearMatch   0.207158  0.376190  1.233114     0.893939   \n",
       "           NIP    IPW         0.060925  0.345514  1.238014     0.929293   \n",
       "           UIP    IPW         0.207905  0.378133  1.236464     0.878788   \n",
       "Scenario 5 NIP    NearMatch   0.060925  0.345514  1.238014     0.929293   \n",
       "           UIP    NearMatch   0.136330  0.375055  1.290145     0.929293   \n",
       "           NIP    IPW         0.060925  0.345514  1.238014     0.929293   \n",
       "           UIP    IPW         0.131011  0.374231  1.288353     0.939394   \n",
       "\n",
       "                                 $w_1$     $w_2$     $w_3$        $M$  \n",
       "Case       Method Bal_Method                                           \n",
       "Scenario 4 NIP    NearMatch        NaN       NaN       NaN        NaN  \n",
       "           UIP    NearMatch   0.527001  0.303782  0.169218  95.718702  \n",
       "           NIP    IPW              NaN       NaN       NaN        NaN  \n",
       "           UIP    IPW         0.544429  0.299113  0.156458  93.798194  \n",
       "Scenario 5 NIP    NearMatch        NaN       NaN       NaN        NaN  \n",
       "           UIP    NearMatch   0.547831  0.260926  0.191242  11.971230  \n",
       "           NIP    IPW              NaN       NaN       NaN        NaN  \n",
       "           UIP    IPW         0.466399  0.312096  0.221505  14.140089  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_all = pd.concat(metrics_dfs)\n",
    "metrics_all.set_index(['Case','Method','Bal_Method'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cccaa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_all.to_csv('./results/{}B_outcome/metric_df_extreme.csv'.format(date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac4e0fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
